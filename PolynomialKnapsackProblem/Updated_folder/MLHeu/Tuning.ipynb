{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ql6keKSXwbE"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKQcTPtmXwbI"
      },
      "source": [
        "df =  pd.read_csv('train.csv', header = 0)\n",
        "df = df._get_numeric_data()\n",
        "numeric_headers = list(df.columns.values)\n",
        "numeric_headers.pop()\n",
        "X = df[numeric_headers]\n",
        "X= X.drop('label', axis=1)\n",
        "X = X.to_numpy()\n",
        "y = df['label']\n",
        "y=y.apply(lambda row: int(row)) \n",
        "y=y.to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X=scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Dh-Cx_XwbI"
      },
      "source": [
        "names = [#\"Nearest_Neighbors\",\n",
        "        #\"SVM\",\n",
        "        \"MLP\",\n",
        "         \"Adaboost\",\n",
        "        \"Random_Forest\"]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMfu9eMhXwbI"
      },
      "source": [
        "classifiers = [\n",
        "    #KNeighborsClassifier(),\n",
        "    #SVC(),\n",
        "    MLPClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    RandomForestClassifier()]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bQrdxPgXwbI"
      },
      "source": [
        "paramsGrid={}\n",
        "paramsGrid[\"SVM\"]={\n",
        "    'C':[0.0001,0.1,1,10,100],\n",
        "    'gamma':[0.001,0.1,1]\n",
        "}\n",
        "paramsGrid[\"Nearest_Neighbors\"]={\n",
        "    'n_neighbors':[1,5,10,50,100,500,1000]\n",
        "}\n",
        "paramsGrid[\"Adaboost\"]={\n",
        "    'n_estimators': [50,100,150,200,250,300]\n",
        "}\n",
        "paramsGrid[\"MLP\"]={\n",
        "    'learning_rate_init':[0.001,0.1,0.01],\n",
        "    'early_stopping':[True],\n",
        "    'hidden_layer_sizes':[100,200,500]\n",
        "}\n",
        "paramsGrid[\"Random_Forest\"]={\n",
        "    'min_samples_leaf': [2,10,30,50],\n",
        "    'min_samples_split': [2,10,30,50],\n",
        "    'n_estimators': [50,100,150,200,250,300]\n",
        "}"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru61WcJvbG2F"
      },
      "source": [
        "def evaluate(model, test_features, test_labels):\n",
        "    ypred = model.predict(test_features)\n",
        "    errors = abs(ypred - test_labels)\n",
        "    accuracy=np.sum([pred == true for pred, true in zip(ypred, test_labels)])/len(test_labels)\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    \n",
        "    return accuracy\n",
        "from google.colab import files"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "4VerWBThgEbE",
        "outputId": "5dee07f3-7847-4eee-d031-d6641bdbbd24"
      },
      "source": [
        "results={}\n",
        "for name, clf in zip(names, classifiers):\n",
        "  print(f\"For classifier {name}\")\t\n",
        "  grid = GridSearchCV(estimator = clf, param_grid = paramsGrid[name], \n",
        "                            cv = 3, n_jobs = -1, verbose = 2)\n",
        "  grid.fit(X_train, y_train)\n",
        "  print(\"\\tBest parameters set found on development set:\")\n",
        "  print()\n",
        "  print(f\"\\t{grid.best_params_}\")\n",
        "  print()\n",
        "  best_grid = grid.best_estimator_\n",
        "  grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
        "  print(\"\\tGrid scores on development set:\")\n",
        "  print()\n",
        "  print(f\"\\t\\t{grid_accuracy}\")\n",
        "  print()\n",
        "  results[name]={\n",
        "      \"best_params\":grid.best_params_,\n",
        "      \"grid_accuracy\":grid_accuracy\n",
        "  }\n",
        "with open(f\"Results_tuning.json\", \"w+\") as f:\n",
        "    json.dump(results,f)\n",
        "files.download(f\"Results_tuning.json\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For classifier MLP\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBest parameters set found on development set:\n",
            "\n",
            "\t{'early_stopping': True, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.001}\n",
            "\n",
            "Model Performance\n",
            "Average Error: 0.0688 degrees.\n",
            "Accuracy = 0.93%.\n",
            "\tGrid scores on development set:\n",
            "\n",
            "\t\t0.931212482189989\n",
            "\n",
            "For classifier Adaboost\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  2.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBest parameters set found on development set:\n",
            "\n",
            "\t{'n_estimators': 50}\n",
            "\n",
            "Model Performance\n",
            "Average Error: 0.0704 degrees.\n",
            "Accuracy = 0.93%.\n",
            "\tGrid scores on development set:\n",
            "\n",
            "\t\t0.929647536963072\n",
            "\n",
            "For classifier Random_Forest\n",
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 33.9min\n",
            "[Parallel(n_jobs=-1)]: Done 288 out of 288 | elapsed: 58.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tBest parameters set found on development set:\n",
            "\n",
            "\t{'min_samples_leaf': 50, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Model Performance\n",
            "Average Error: 0.0684 degrees.\n",
            "Accuracy = 0.93%.\n",
            "\tGrid scores on development set:\n",
            "\n",
            "\t\t0.9316329152360264\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_166fa235-5c89-4ded-afa0-f216048425e6\", \"Results_tuning.json\", 371)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}